library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
##Load data
p <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
d <- read.csv("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/tests-by-zcta.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1, 4)
##Rename to merge
d <- d %>% rename(ZIPCODE = MODZCTA)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='ZIPCODE')
##Positive per capita
m$positivepercapita <- (m$Positive / m$POPULATION)*100
m$positivepercapita[is.na(m$valuepercapita)] = 0
m$positiveepercapita <- format(round(m$positivepercapita, 2), nsmall = 2)
##Total per capita
m$totalpercapita <- (m$Total / m$POPULATION)*100
m$totalpercapita[is.na(m$valuepercapita)] = 0
m$totalpercapita <- format(round(m$totalpercapita, 2), nsmall = 2)
##Write as GeoJSON
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON")
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library (readr)
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
geography <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
data<-read_csv(url(urlfile))
##Remove unncessary columns
geography@data <- geography@data %>% select(1, 4)
View(data)
data <- data %>% rename(ZIPCODE = MODZCTA)
merged <- merge(geography, data, by='ZIPCODE')
View(merged)
merged$positivepercapita <- (merged$Positive / merged$POPULATION)*100
merged$positivepercapita[is.na(merged$valuepercapita)] = 0
merged$positiveepercapita <- format(round(merged$positivepercapita, 2), nsmall = 2)
View(merged)
merged$positivepercapita <- format(round(merged$positivepercapita, 2), nsmall = 2)
##Total per capita
merged$totalpercapita <- (merged$Total / merged$POPULATION)*100
merged$totalpercapita[is.na(merged$valuepercapita)] = 0
merged$totalpercapita <- format(round(merged$totalpercapita, 2), nsmall = 2)
##Write as GeoJSON
writeOGR(merged, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/", layer="merged", driver="GeoJSON")
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library (readr)
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
d<-read_csv(url(urlfile))
##Remove unncessary columns
p@data <- geography@data %>% select(1, 4)
##Rename to merge
d <- d %>% rename(ZIPCODE = MODZCTA)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='ZIPCODE')
##Positive per capita
m$positivepercapita <- (m$Positive / m$POPULATION)*100
m$positivepercapita[is.na(m$valuepercapita)] = 0
m$positivepercapita <- format(round(m$positivepercapita, 2), nsmall = 2)
##Total per capita
m$totalpercapita <- (m$Total / m$POPULATION)*100
m$totalpercapita[is.na(m$valuepercapita)] = 0
m$totalpercapita <- format(round(m$totalpercapita, 2), nsmall = 2)
##Write as GeoJSON
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON")
##Write as GeoJSON
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON", overwrite_layer=TRUE)
writeOGR(merged, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/", layer="2", driver="GeoJSON")
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library (readr)
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
geography <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
data<-read_csv(url(urlfile))
##Remove unncessary columns
geography@data <- geography@data %>% select(1, 4)
##Rename to merge
data <- data %>% rename(ZIPCODE = MODZCTA)
##Merge Zip Code shapefile with Testing data (DOHMH)
merged <- merge(geography, data, by='ZIPCODE')
##Positive per capita
merged$positivepercapita <- (merged$Positive / merged$POPULATION)*100
merged$positivepercapita[is.na(merged$valuepercapita)] = 0
merged$positiveepercapita <- format(round(merged$positivepercapita, 2), nsmall = 2)
##Total per capita
merged$totalpercapita <- (merged$Total / merged$POPULATION)*100
merged$totalpercapita[is.na(merged$valuepercapita)] = 0
merged$totalpercapita <- format(round(merged$totalpercapita, 2), nsmall = 2)
writeOGR(merged, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/", layer="2", driver="GeoJSON")
##Write as GeoJSON
writeOGR(merged, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/", layer="HELLO", driver="GeoJSON")
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library (readr)
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
d<-read_csv(url(urlfile))
##Remove unncessary columns
p@data <- geography@data %>% select(1, 4)
##Rename to merge
d <- d %>% rename(ZIPCODE = MODZCTA)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='ZIPCODE')
##Positive per capita
m$positivepercapita <- (m$Positive / m$POPULATION)*100
m$positivepercapita[is.na(m$valuepercapita)] = 0
m$positiveepercapita <- format(round(m$positivepercapita, 2), nsmall = 2)
##Total per capita
m$totalpercapita <- (m$Total / m$POPULATION)*100
m$totalpercapita[is.na(m$valuepercapita)] = 0
m$totalpercapita <- format(round(m$totalpercapita, 2), nsmall = 2)
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON")
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library (readr)
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/ZIP_CODE_040114/ZIP_CODE_040114.shp")
d<-read_csv(url(urlfile))
##Remove unncessary columns
p@data <- geography@data %>% select(1, 4)
##Rename to merge
d <- d %>% rename(ZIPCODE = MODZCTA)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='ZIPCODE')
##Positive per capita
m$positivepercapita <- (m$Positive / m$POPULATION)*100
m$positivepercapita[is.na(m$valuepercapita)] = 0
m$positivepercapita <- format(round(m$positivepercapita, 2), nsmall = 2)
##Total per capita
m$totalpercapita <- (m$Total / m$POPULATION)*100
m$totalpercapita[is.na(m$valuepercapita)] = 0
m$totalpercapita <- format(round(m$totalpercapita, 2), nsmall = 2)
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON")
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/test", layer="m", driver="GeoJSON")
##Write as GeoJSON
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/2", layer="m", driver="GeoJSON")
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/", layer="m", driver="GeoJSON", overwrite_layer=TRUE)
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test/", layer="m", driver="GeoJSON", overwrite_layer=TRUE)
##Write as GeoJSON
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test.geojson", layer="m", driver="GeoJSON", overwrite_layer=TRUE)
writeOGR(m, "C:/Users/jaramana/Desktop/COVID Tracker NYC/data/test/test.geojson", layer="m", driver="GeoJSON", overwrite_layer=TRUE)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
View(cw)
##Rename column header to merge
d <- d %>% rename(zcta = ZIP)
##Rename column header to merge
cw <- cw %>% rename(zcta = ZIP)
View(cw)
View(d)
join(cw, d, by = "zcta")
join(cw, d, by = "zcta")
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
join(cw, d, by = "zcta")
library(plyr)
data_2012 = merge(cw[, c("zcta", "Positive")],
d[, c("zcta", "TOT_RATIO")])
data_2012 = merge(cw[, c("zcta", "TOT_RATIO")],
d[, c("zcta", "Positive")])
d <- d %>% rename(zcta = MODZCTA)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
d <- d %>% rename(MODZCTA = MODZCTA)
##Rename column header to merge
d <- d %>% rename(MODZCTA = he)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
View(d)
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
##Load package
library(raster)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
d <- d %>% rename(zcta = MODZCTA)
rename(d, zcta = MODZCTA)
rename(d, MODZCTA = MODZCTA)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
##Sum duplicate zipcodes (sometimes happens)
d <- aggregate(list(d$'Positive', d$'Total'), by = list(d$'zcta'), sum)
d <- rename(d, 'zcta' = 1)
d <- rename(d, 'Positive' = 2)
d <- rename(d, 'Total' = 3)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='zcta')
##Merge Spatial data with neighborhood names
m <- merge(m, n, by='zcta')
##Merge Spatial data with census data
m <- merge(m, c, by='zcta')
m$Positive[ is.na(m$Positive)] = 0
m$Total[ is.na(m$Total)] = 0
##Positive per capita
m$positiveperthou <- (m$Positive / m$population)*1000
m$positiveperthou[ is.na(m$positiveperthou)] = 0
m$positiveperthou <- format(round(m$positiveperthou, 2), nsmall = 2)
m$positiveperthou <- as.numeric(m$positiveperthou)
##Total per capita
m$totalperthou <- (m$Total / m$population)*1000
m$totalperthou[is.na(m$totalperthou)] = 0
m$totalperthou <- format(round(m$totalperthou, 2), nsmall = 2)
m$totalperthou <- as.numeric(m$totalperthou)
##Assign CRS
m <- spTransform(m, CRS("+proj=longlat +datum=WGS84 +init=epsg:4269"))
##Write as GeoJSON
writeOGR(m, "data/covid_nyc.json", layer="merged", driver="GeoJSON", overwrite_layer=TRUE)
##Get quantiles for breaks / legend
quantile(m$totalperthou, probs = seq(0, 1, .20))
##Chart--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/case-hosp-death.csv"
##Load data
d <- read_csv(url(urlfile))
##Change NA to 0
d[is.na(d)] <- 0
##Rename column header (sometimes DOHMH messes this up)
d <- rename(d, 'DATE_OF_INTEREST' = 1)
##Create new columns with cumulative sums
d[,"NEW_COVID_CASE_COUNT_CUM"] <- cumsum(d$NEW_COVID_CASE_COUNT)
d[,"HOSPITALIZED_CASE_COUNT_CUM"] <- cumsum(d$HOSPITALIZED_CASE_COUNT)
d[,"DEATH_COUNT_CUM"] <- cumsum(d$DEATH_COUNT)
##Write as json
write_json(d, "data/case-hosp-death_cumulative.json", pretty = TRUE)
##Write as csv for public use
write.csv(d, "download/case-hosp-death_cumulative.csv", row.names = FALSE)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
d <- d %>% rename('zcta' = 'MODZCTA')
##Rename column header to merge
d <- d %>% rename('zcta' = 'MODZCTA')
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
ct <- shapefile("data/raw/tl_2017_36_tract_clipped/tl_2017_36_tract_clipped")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
cw <- read_csv("data/raw/ZIP_TRACT_122010.csv")
##Rename column header to merge
cw <- cw %>% rename(zcta = ZIP)
cw <- cw %>% rename(GEOID = TRACT)
d <- d %>% rename(zcta = MODZCTA)
data_2012 = merge(cw[, c("zcta", "GEOID", "TOT_RATIO")],
d[, c("zcta", "Positive")])
data_2012$number <- data_2012$Positive * data_2012$TOT_RATIO
data_pivot = group_by(data_2012, GEOID)
data_pivot = summarise(data_pivot,
sum = sum(number))
##Merge Zip Code shapefile with Testing data (DOHMH)
options(scipen=999)
View(data_pivot)
View(ct)
View(ct)
##Load package
library(raster)
library(rgdal)
library(tidyverse)
library(dplyr)
library(readr)
library(jsonlite)
##Set working directory
setwd("C:/Users/jaramana/Desktop/covid-tracker-nyc")
##Spatial Visualization--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/tests-by-zcta.csv"
##Load data
p <- shapefile("data/raw/nyu_2451_34509_filtered/nyu_2451_34509_filtered")
d <- read_csv(url(urlfile))
c <- read_csv("data/raw/ACS2015_zctaallvars_modified.csv")
n <- read_csv("data/raw/zcta_neighborhood_names.csv")
##Remove unncessary columns
p@data <- p@data %>% select(1)
##Remove unncessary columns
d <- d %>% select(1,2,3)
##Rename column header to merge
d <- d %>% rename(zcta = MODZCTA)
##Sum duplicate zipcodes (sometimes happens)
d <- aggregate(list(d$'Positive', d$'Total'), by = list(d$'zcta'), sum)
d <- rename(d, 'zcta' = 1)
d <- rename(d, 'Positive' = 2)
d <- rename(d, 'Total' = 3)
##Merge Zip Code shapefile with Testing data (DOHMH)
m <- merge(p, d, by='zcta')
##Merge Spatial data with neighborhood names
m <- merge(m, n, by='zcta')
##Merge Spatial data with census data
m <- merge(m, c, by='zcta')
m$Positive[ is.na(m$Positive)] = 0
m$Total[ is.na(m$Total)] = 0
##Positive per capita
m$positiveperthou <- (m$Positive / m$population)*1000
m$positiveperthou[ is.na(m$positiveperthou)] = 0
m$positiveperthou <- format(round(m$positiveperthou, 2), nsmall = 2)
m$positiveperthou <- as.numeric(m$positiveperthou)
##Total per capita
m$totalperthou <- (m$Total / m$population)*1000
m$totalperthou[is.na(m$totalperthou)] = 0
m$totalperthou <- format(round(m$totalperthou, 2), nsmall = 2)
m$totalperthou <- as.numeric(m$totalperthou)
##Assign CRS
m <- spTransform(m, CRS("+proj=longlat +datum=WGS84 +init=epsg:4269"))
##Write as GeoJSON
writeOGR(m, "data/covid_nyc.json", layer="merged", driver="GeoJSON", overwrite_layer=TRUE)
##Get quantiles for breaks / legend
quantile(m$totalperthou, probs = seq(0, 1, .20))
##Chart--
##Link to DOHMH Github Data
urlfile="https://raw.githubusercontent.com/nychealth/coronavirus-data/master/case-hosp-death.csv"
##Load data
d <- read_csv(url(urlfile))
##Change NA to 0
d[is.na(d)] <- 0
##Rename column header (sometimes DOHMH messes this up)
d <- rename(d, 'DATE_OF_INTEREST' = 1)
##Create new columns with cumulative sums
d[,"NEW_COVID_CASE_COUNT_CUM"] <- cumsum(d$NEW_COVID_CASE_COUNT)
d[,"HOSPITALIZED_CASE_COUNT_CUM"] <- cumsum(d$HOSPITALIZED_CASE_COUNT)
d[,"DEATH_COUNT_CUM"] <- cumsum(d$DEATH_COUNT)
##Write as json
write_json(d, "data/case-hosp-death_cumulative.json", pretty = TRUE)
##Write as csv for public use
write.csv(d, "download/case-hosp-death_cumulative.csv", row.names = FALSE)
